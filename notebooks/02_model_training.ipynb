{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network Classifier: Step-by-Step\n",
    "\n",
    "To train a neural network classifier, we follow these steps:\n",
    "\n",
    "1. **Load Cleaned Data**: Start by loading the cleaned dataset.\n",
    "\n",
    "2. **Define Hyperparameters and Data Splits**: Set the hyperparameters (e.g., learning rate, batch size) and split the data into training and testing sets. We also choose the specific labels for which we will train classifiers. Each label will have its own classifier.\n",
    "\n",
    "3. **Retrieve Tweet Embeddings**: Load or generate tweet embeddings using a pre-trained model (e.g., GPT-4).\n",
    "\n",
    "4. **Define Dataset, Model and Trainig loop**: Define the dataset and the neural network model according to Pytorch specifications which simplfy the training process dataloading and model training. Also create the functions that takes in all of this and trains the model.\n",
    "\n",
    "5. **Train the Classifier**: Load the neural network classifier and train it using the selected hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613, 39)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>post</th>\n",
       "      <th>permalink</th>\n",
       "      <th>reposts</th>\n",
       "      <th>likes</th>\n",
       "      <th>impressions</th>\n",
       "      <th>quotes</th>\n",
       "      <th>replies</th>\n",
       "      <th>bookmarks</th>\n",
       "      <th>value</th>\n",
       "      <th>report_file</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>relevance</th>\n",
       "      <th>anti RSF</th>\n",
       "      <th>pro RSF</th>\n",
       "      <th>anti SAF</th>\n",
       "      <th>pro SAF</th>\n",
       "      <th>Pro peace,</th>\n",
       "      <th>anti peace</th>\n",
       "      <th>Pro War</th>\n",
       "      <th>anti war</th>\n",
       "      <th>pro civilian</th>\n",
       "      <th>anti civilians</th>\n",
       "      <th>not specified</th>\n",
       "      <th>no polarisation</th>\n",
       "      <th>Geopolticis</th>\n",
       "      <th>Sudanese</th>\n",
       "      <th>Not Sudanese</th>\n",
       "      <th>Sudanese N/A</th>\n",
       "      <th>Likely bot</th>\n",
       "      <th>Likely not a bot</th>\n",
       "      <th>Cannot be identified.</th>\n",
       "      <th>News</th>\n",
       "      <th>Not about Sudan</th>\n",
       "      <th>Annotation Confidence</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>☬ود نيـالا ☬</td>\n",
       "      <td>@Mo7amedWagi7</td>\n",
       "      <td>2023-04-15 15:29:44</td>\n",
       "      <td>@OmerElameen2 @drhzagalo لما يكون عندك حكومة و...</td>\n",
       "      <td>https://www.twitter.com/user/status/1647260928...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>Report 1-1</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>15:29:44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1647260928231055360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عربي21</td>\n",
       "      <td>@Arabi21News</td>\n",
       "      <td>2023-08-28 20:02:00</td>\n",
       "      <td>الخارجية السودانية توضح لـ\"عربي21\" حقيقة زيارة...</td>\n",
       "      <td>https://www.twitter.com/user/status/1696251807...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3402</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3115.19</td>\n",
       "      <td>Report 3-2</td>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>20:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1696251807083758021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تحالف عاصفة الحزم</td>\n",
       "      <td>@AaSsiFfah2015</td>\n",
       "      <td>2023-04-15 22:52:29</td>\n",
       "      <td>#السودان \\nنشرة المستشفيات:\\nالحرب حتى الآن تس...</td>\n",
       "      <td>https://www.twitter.com/user/status/1647372349...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.58</td>\n",
       "      <td>Report 1-3</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>22:52:29</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1647372349585358848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H_Lamami</td>\n",
       "      <td>@HLamami2</td>\n",
       "      <td>2023-04-15 13:36:46</td>\n",
       "      <td>■اذا رايت الاخوان يحبون حميدتي ويطبلون له\\nفاع...</td>\n",
       "      <td>https://www.twitter.com/user/status/1647232497...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>Report 1-2</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>13:36:46</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1647232497238028289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وفاء علي</td>\n",
       "      <td>@eali_wafa15327</td>\n",
       "      <td>2023-08-29 12:17:05</td>\n",
       "      <td>@taherabdulwhab @Mohmd_Elsiddig @saramubael م ...</td>\n",
       "      <td>https://www.twitter.com/user/status/1696497195...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Report 3-1</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>12:17:05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1696497195434881292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user         username            timestamp  \\\n",
       "0       ☬ود نيـالا ☬    @Mo7amedWagi7  2023-04-15 15:29:44   \n",
       "1             عربي21     @Arabi21News  2023-08-28 20:02:00   \n",
       "2  تحالف عاصفة الحزم   @AaSsiFfah2015  2023-04-15 22:52:29   \n",
       "3           H_Lamami        @HLamami2  2023-04-15 13:36:46   \n",
       "4           وفاء علي  @eali_wafa15327  2023-08-29 12:17:05   \n",
       "\n",
       "                                                post  \\\n",
       "0  @OmerElameen2 @drhzagalo لما يكون عندك حكومة و...   \n",
       "1  الخارجية السودانية توضح لـ\"عربي21\" حقيقة زيارة...   \n",
       "2  #السودان \\nنشرة المستشفيات:\\nالحرب حتى الآن تس...   \n",
       "3  ■اذا رايت الاخوان يحبون حميدتي ويطبلون له\\nفاع...   \n",
       "4  @taherabdulwhab @Mohmd_Elsiddig @saramubael م ...   \n",
       "\n",
       "                                           permalink  reposts  likes  \\\n",
       "0  https://www.twitter.com/user/status/1647260928...        0      1   \n",
       "1  https://www.twitter.com/user/status/1696251807...        1      5   \n",
       "2  https://www.twitter.com/user/status/1647372349...        0      1   \n",
       "3  https://www.twitter.com/user/status/1647232497...        0      0   \n",
       "4  https://www.twitter.com/user/status/1696497195...        0      4   \n",
       "\n",
       "   impressions  quotes  replies  bookmarks    value report_file        date  \\\n",
       "0          310       0        0          0     0.03  Report 1-1  2023-04-15   \n",
       "1         3402       1        1          0  3115.19  Report 3-2  2023-08-28   \n",
       "2          472       0        0          0    15.58  Report 1-3  2023-04-15   \n",
       "3           72       0        0          0     4.04  Report 1-2  2023-04-15   \n",
       "4           30       0        1          0     0.05  Report 3-1  2023-08-29   \n",
       "\n",
       "       time  relevance  anti RSF  pro RSF  anti SAF  pro SAF  Pro peace,  \\\n",
       "0  15:29:44          1       0.0      0.0       0.0      0.0         0.0   \n",
       "1  20:02:00          1       0.0      0.0       0.0      0.0         0.0   \n",
       "2  22:52:29          1       1.0      0.0       0.0      0.0         0.0   \n",
       "3  13:36:46          1       1.0      0.0       0.0      0.0         0.0   \n",
       "4  12:17:05          1       1.0      0.0       0.0      0.0         1.0   \n",
       "\n",
       "   anti peace  Pro War  anti war  pro civilian  anti civilians  not specified  \\\n",
       "0         0.0      0.0       0.0           0.0             0.0            1.0   \n",
       "1         0.0      0.0       0.0           0.0             0.0            0.0   \n",
       "2         1.0      1.0       0.0           0.0             0.0            0.0   \n",
       "3         0.0      1.0       0.0           0.0             0.0            0.0   \n",
       "4         0.0      0.0       0.0           0.0             0.0            0.0   \n",
       "\n",
       "   no polarisation  Geopolticis  Sudanese  Not Sudanese  Sudanese N/A  \\\n",
       "0              0.0          1.0       1.0           0.0           0.0   \n",
       "1              0.0          0.0       0.0           0.0           0.0   \n",
       "2              0.0          0.0       0.0           0.0           1.0   \n",
       "3              0.0          1.0       0.0           1.0           0.0   \n",
       "4              0.0          0.0       1.0           0.0           0.0   \n",
       "\n",
       "   Likely bot  Likely not a bot  Cannot be identified.  News  Not about Sudan  \\\n",
       "0         0.0               1.0                    0.0   0.0                0   \n",
       "1         0.0               0.0                    0.0   1.0                0   \n",
       "2         0.0               1.0                    0.0   0.0                0   \n",
       "3         1.0               0.0                    1.0   0.0                0   \n",
       "4         0.0               1.0                    0.0   0.0                0   \n",
       "\n",
       "   Annotation Confidence                 code  \n",
       "0                    9.0  1647260928231055360  \n",
       "1                   10.0  1696251807083758021  \n",
       "2                    8.0  1647372349585358848  \n",
       "3                    8.0  1647232497238028289  \n",
       "4                    8.0  1696497195434881292  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# Load the cleaned data\n",
    "data = pd.read_csv('../data/cleaned_data.csv')\n",
    "\n",
    "#Display the first 5 rows of the data and the shape of the data\n",
    "display(data.shape)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Define Hyperparameters and Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(613, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Function to get the X and Y values from the dataframe. X is the tweets and Y is the labels\n",
    "def get_xy(df, tweets_col, labels_cols):\n",
    "    X = df[tweets_col].reset_index(drop=True)\n",
    "    if labels_cols:\n",
    "        Y = df[labels_cols].reset_index(drop=True)\n",
    "    else:\n",
    "        Y = df.drop(columns=['post']).reset_index(drop=True)\n",
    "    codes = df['code'].reset_index(drop=True)\n",
    "    return X, Y, codes\n",
    "\n",
    "# Function to merge the pro and anti columns into a single column with values 0, 1 and 2\n",
    "def merge_pro_anti(df, pro_col, anti_col):\n",
    "    pro = df[pro_col].values.tolist()\n",
    "    anti = df[anti_col].values.tolist()\n",
    "    merged = []\n",
    "    for i in range(len(pro)):\n",
    "        if pro[i] == 1 and anti[i] == 0:\n",
    "            merged.append(1)\n",
    "        elif pro[i] == 0 and anti[i] == 1:\n",
    "            merged.append(0)\n",
    "        elif pro[i] == 0 and anti[i] == 0:\n",
    "            merged.append(2)\n",
    "        else:\n",
    "            print(f' row {i} has both pro and anti')\n",
    "            merged.append(2)\n",
    "    return merged\n",
    "\n",
    "# Set the accelerator to be used to one of 'cuda', 'mps' or 'cpu' based on availability\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# The Classifiers can be binary (0, 1) or ternary (0, 1, 2).You can select which labels to merge into ternary and which to keep binary\n",
    "data['RSF'] = merge_pro_anti(data, 'pro RSF', 'anti RSF')\n",
    "data['SAF'] = merge_pro_anti(data, 'pro SAF', 'anti SAF')\n",
    "# Select the Labels for which we want to train the classifier. One classifier will be trained for each label\n",
    "labels = ['RSF', 'SAF', 'Pro peace,', 'anti peace',\n",
    "          'Pro War', 'anti war', 'pro civilian', 'anti civilians', \n",
    "          'no polarisation', 'Geopolticis', 'Sudanese', 'Not Sudanese', 'anti RSF', 'pro RSF', 'anti SAF', 'pro SAF', ]\n",
    "labels = labels[:4] # Remove this line, only here to speed up the training Using labels SAF and RSF (ternary) and Pro peace and anti peace (binary)\n",
    "\n",
    "\n",
    "# Set the parameters for the training\n",
    "test_size = 0.25 # Fraction of the data to be used for testing\n",
    "random_state = 42 # Random state for reproducibility\n",
    "n_splits = 5 # Number of splits for the cross validation\n",
    "num_epochs = 5 # Number of epochs for training\n",
    "batch_size = 256 # Batch size for training\n",
    "hidden_dim = 1024 # Hidden dimension for the classifier\n",
    "learning_rate = 1e-5 # Learning rate for the optimizer\n",
    "\n",
    "# Get the X, Y and codes values. X is the tweets, Y is the labels and codes is the unique identifier for each tweet used later to retrieve its embeddings.\n",
    "X, Y, codes = get_xy(data, tweets_col='post', labels_cols=labels)\n",
    "\n",
    "# Display the shape of the X and Y values\n",
    "display(X.shape, Y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Retrieve Tweet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loading Saved OpenAI Embeddings'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([613, 3072])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Function to get the OpenAI embeddings for the tweets in the data using the OpenAI API then save them to a parquet file\n",
    "def save_openai_embs(df, api_key, model=\"text-embedding-3-large\"):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    codes, tweets, large_embs = [], [], []\n",
    "    for i,row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        tweet = row['post']\n",
    "        code = row['code']\n",
    "        response = client.embeddings.create(input=tweet,model=model)\n",
    "        emb = response.data[0].embedding\n",
    "        large_embs.append(emb)\n",
    "        codes.append(str(code))\n",
    "        tweets.append(tweet)\n",
    "    embeddings_df = pd.DataFrame({'code': codes, 'tweet': tweets, 'embedding': large_embs})\n",
    "    embeddings_df = embeddings_df.set_index('code', drop=True)\n",
    "    os.makedirs('../embeddings', exist_ok=True)\n",
    "    embeddings_df.to_parquet('../embeddings/labelled_embeddings.parquet')\n",
    "    return embeddings_df\n",
    "\n",
    "# Transoform the embeddings to a tensor based on the tweets in the data using their unique codes\n",
    "def embeddings_tensor(codes, embs, device):\n",
    "    tweets_embeddings = []\n",
    "    for i in range(len(codes)):\n",
    "        code = str(codes[i])\n",
    "        row = embs.loc[code]\n",
    "        tweets_embeddings.append(row['embedding'])\n",
    "    tweets_embeddings = torch.tensor(tweets_embeddings, device=device, dtype=torch.float32)\n",
    "    return tweets_embeddings\n",
    "\n",
    "\n",
    "# Load the OpenAI embeddings if they exist\n",
    "if os.path.exists('../embeddings/labelled_embeddings.parquet'):\n",
    "    display('Loading Saved OpenAI Embeddings')\n",
    "    openai_embs = pd.read_parquet('../embeddings/labelled_embeddings.parquet')\n",
    "else:\n",
    "    # Get the OpenAI embeddings for the tweets in the data using the OpenAI API then save them to a parquet file\n",
    "    display('OpenAI Embeddings not found, using the API to get the embeddings')\n",
    "    openai_embs = save_openai_embs(data, api_key='<sk-xxxxxx>') # Replace <sk-xxxxxx> with your OpenAI API key\n",
    "\n",
    "# Get the embeddings tensor for the tweets in the data\n",
    "embs = embeddings_tensor(codes, openai_embs, device)\n",
    "\n",
    "# Get the embeddings dimension which will be used as the input size for the classifier\n",
    "embeddings_dim = embs.shape[1]\n",
    "\n",
    "# Display the shape of the embeddings tensor\n",
    "display(embs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Define Dataset, Model and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Function that takes a model, a dataloader, the number of classes and the device and returns the scores for the model\n",
    "def score_model(model, dataloader, multi_calss, device):\n",
    "    model.eval()\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)['probs']\n",
    "            ground_truth.append(y)\n",
    "            predictions.append(y_pred)\n",
    "    ground_truth = torch.concat(ground_truth).detach().cpu()\n",
    "    predictions = torch.concat(predictions).detach().cpu()\n",
    "    gt = [yp.item() for yp in ground_truth]\n",
    "    preds = [yp.argmax().item() for yp in predictions]\n",
    "    acc = accuracy_score(gt, preds)\n",
    "    f1 = f1_score(gt, preds, average='weighted')\n",
    "    if multi_calss == 'raise':\n",
    "        predictions = torch.tensor([yp.argmax().item() for yp in predictions])\n",
    "    rocauc = roc_auc_score(ground_truth, predictions, multi_class=multi_calss)\n",
    "    predictions = torch.where(predictions > 0.5, 1, 0).type(torch.float32)\n",
    "    scores = {\n",
    "        'rocauc': rocauc,\n",
    "        'accuracy': acc,\n",
    "        'f1': f1\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "# Create a Dataset class for the tweets and their labels\n",
    "class TweetsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# Create a Classifier Neural Network class the defines the architecture of the classifier based on the input dimension, number of classes and hidden dimension\n",
    "class TweetClassifer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim) # input dim -> 512\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.hidden_dim//2) # 512 -> 256\n",
    "        self.fc3 = nn.Linear(self.hidden_dim//2, self.hidden_dim//4) # 256 -> 128\n",
    "        self.fc4 = nn.Linear(self.hidden_dim//4, self.hidden_dim//8) # 128 -> 64\n",
    "        self.fc5 = nn.Linear(self.hidden_dim//8, self.num_classes) # 64 -> num_classe\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        logits = self.fc5(x)\n",
    "        x = self.softmax(logits)\n",
    "        return {'logits': logits, 'probs': x}\n",
    "    \n",
    "# Function to train the classifier using the dataloaders\n",
    "def train(model, train_dataloader, val_dataloader, num_epochs, optimizer, loss_fn, num_classes,model_name, device):\n",
    "    # Initialize the logs to store the training and validation metrics\n",
    "    logs = {'train_loss': [], 'val_loss': [], 'train_rocauc':[], 'val_rocauc':[], 'train_acc':[], 'val_acc':[], 'train_f1':[], 'val_f1':[]}\n",
    "    # Initialize the best accuracy to 0, used to save the best model\n",
    "    acc_max = 0\n",
    "    # Train the model for the number of epochs\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # Set the model to training mode and iterate over the training dataloader updating the weights\n",
    "        model.train()\n",
    "        for x, y in train_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)['logits']\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Every 5 epochs, evaluate the model on the validation set and save the model if the accuracy is higher than the previous best\n",
    "        if epoch%5 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for x, y in val_dataloader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    y_pred = model(x)['logits']\n",
    "                    val_loss += loss_fn(y_pred, y)\n",
    "            # Get the scores for the model on the training and validation sets\n",
    "            multi_class = 'raise' if num_classes == 2 else 'ovo'\n",
    "            train_scores = score_model(model, train_dataloader, multi_calss=multi_class, device=device)\n",
    "            val_scores = score_model(model, val_dataloader, multi_calss=multi_class, device=device)\n",
    "            train_rocauc, val_rocauc = train_scores['rocauc'], val_scores['rocauc']\n",
    "            train_acc, val_acc = train_scores['accuracy'], val_scores['accuracy']\n",
    "            train_f1, val_f1 = train_scores['f1'], val_scores['f1']\n",
    "            # Save the model if the validation accuracy is higher than the previous best\n",
    "            if val_acc > acc_max:\n",
    "                acc_max = val_acc\n",
    "                torch.save(model.state_dict(), f'../models/best_{model_name}.pth')\n",
    "                print(f'>>> Best VAL ACC so far: {acc_max} at epoch {epoch} with train aucroc {train_rocauc} , train acc {train_acc} and val rocauc {val_rocauc} saved to ./models/best_{model_name}.pth')\n",
    "            # Print the training and validation metrics\n",
    "            print(f'Epoch: {epoch} -- Train Loss: {loss.item() :.4f} RocAuc = {train_rocauc*100 :.4f} Acc = {train_acc*100 :.4f}|| Val Loss: {val_loss.item() :.4f} RocAuc = {val_rocauc*100 :.4f} Acc = {val_acc*100 :.4f}')\n",
    "            logs['train_loss'].append(loss.item())\n",
    "            logs['val_loss'].append(val_loss.item())\n",
    "            logs['train_rocauc'].append(train_rocauc)\n",
    "            logs['val_rocauc'].append(val_rocauc)\n",
    "            logs['train_acc'].append(train_acc)\n",
    "            logs['val_acc'].append(val_acc)\n",
    "            logs['train_f1'].append(train_f1)\n",
    "            logs['val_f1'].append(val_f1)\n",
    "    # Save the model after training\n",
    "    torch.save(model.state_dict(), f'../models/lattest_{model_name}.pth')\n",
    "    print(f'>>> Finished training {model_name} model and saved to ./models/lattest_{model_name}.pth, final metrics: train aucroc {train_rocauc} , train acc {train_acc} and val acc {val_acc}')\n",
    "    return model, logs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Train the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training model for RSF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b9eb9e117742089cb29a54bb84b866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.6422764227642277 at epoch 0 with train aucroc 0.6252563344178251 , train acc 0.6428571428571429 and val rocauc 0.4916798523206751 saved to ./models/best_clf_RSF_split_0.pth\n",
      "Epoch: 0 -- Train Loss: 1.1010 RocAuc = 62.5256 Acc = 64.2857|| Val Loss: 1.0993 RocAuc = 49.1680 Acc = 64.2276\n",
      ">>> Finished training clf_RSF_split_0 model and saved to ./models/lattest_clf_RSF_split_0.pth, final metrics: train aucroc 0.6252563344178251 , train acc 0.6428571428571429 and val acc 0.6422764227642277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873929bace4d4ec28481dee8fda6f4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.032520325203252036 at epoch 0 with train aucroc 0.6471392421702981 , train acc 0.02857142857142857 and val rocauc 0.6409150843881857 saved to ./models/best_clf_RSF_split_1.pth\n",
      "Epoch: 0 -- Train Loss: 1.0939 RocAuc = 64.7139 Acc = 2.8571|| Val Loss: 1.0974 RocAuc = 64.0915 Acc = 3.2520\n",
      ">>> Finished training clf_RSF_split_1 model and saved to ./models/lattest_clf_RSF_split_1.pth, final metrics: train aucroc 0.6471392421702981 , train acc 0.02857142857142857 and val acc 0.032520325203252036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4c92f3b1c343ae9f7078d9ea5cca63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.032520325203252036 at epoch 0 with train aucroc 0.6177018633540373 , train acc 0.02857142857142857 and val rocauc 0.5020569620253165 saved to ./models/best_clf_RSF_split_2.pth\n",
      "Epoch: 0 -- Train Loss: 1.0993 RocAuc = 61.7702 Acc = 2.8571|| Val Loss: 1.0982 RocAuc = 50.2057 Acc = 3.2520\n",
      ">>> Finished training clf_RSF_split_2 model and saved to ./models/lattest_clf_RSF_split_2.pth, final metrics: train aucroc 0.6177018633540373 , train acc 0.02857142857142857 and val acc 0.032520325203252036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4461e837ede4625810ad987bc6e06c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.02459016393442623 at epoch 0 with train aucroc 0.6336276797353402 , train acc 0.03054989816700611 and val rocauc 0.48245428973277077 saved to ./models/best_clf_RSF_split_3.pth\n",
      "Epoch: 0 -- Train Loss: 1.0943 RocAuc = 63.3628 Acc = 3.0550|| Val Loss: 1.1025 RocAuc = 48.2454 Acc = 2.4590\n",
      ">>> Finished training clf_RSF_split_3 model and saved to ./models/lattest_clf_RSF_split_3.pth, final metrics: train aucroc 0.6336276797353402 , train acc 0.03054989816700611 and val acc 0.02459016393442623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d17204968ab468bbfdb50e6ddddc3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.02459016393442623 at epoch 0 with train aucroc 0.572392317158931 , train acc 0.03054989816700611 and val rocauc 0.6244354110207769 saved to ./models/best_clf_RSF_split_4.pth\n",
      "Epoch: 0 -- Train Loss: 1.0980 RocAuc = 57.2392 Acc = 3.0550|| Val Loss: 1.0989 RocAuc = 62.4435 Acc = 2.4590\n",
      ">>> Finished training clf_RSF_split_4 model and saved to ./models/lattest_clf_RSF_split_4.pth, final metrics: train aucroc 0.572392317158931 , train acc 0.03054989816700611 and val acc 0.02459016393442623\n",
      ">>> Training model for SAF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64305ffa35264d139942225c02ea89a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.15447154471544716 at epoch 0 with train aucroc 0.48640025160295436 , train acc 0.1510204081632653 and val rocauc 0.5130927285915047 saved to ./models/best_clf_SAF_split_0.pth\n",
      "Epoch: 0 -- Train Loss: 1.1113 RocAuc = 48.6400 Acc = 15.1020|| Val Loss: 1.0997 RocAuc = 51.3093 Acc = 15.4472\n",
      ">>> Finished training clf_SAF_split_0 model and saved to ./models/lattest_clf_SAF_split_0.pth, final metrics: train aucroc 0.48640025160295436 , train acc 0.1510204081632653 and val acc 0.15447154471544716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4695f98b294dd48b34093635b26615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.14634146341463414 at epoch 0 with train aucroc 0.5752991179114707 , train acc 0.15306122448979592 and val rocauc 0.5088654290765674 saved to ./models/best_clf_SAF_split_1.pth\n",
      "Epoch: 0 -- Train Loss: 1.1192 RocAuc = 57.5299 Acc = 15.3061|| Val Loss: 1.1036 RocAuc = 50.8865 Acc = 14.6341\n",
      ">>> Finished training clf_SAF_split_1 model and saved to ./models/lattest_clf_SAF_split_1.pth, final metrics: train aucroc 0.5752991179114707 , train acc 0.15306122448979592 and val acc 0.14634146341463414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b44523a02db4d96b374cd22c819ffd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.6991869918699187 at epoch 0 with train aucroc 0.5439130995932245 , train acc 0.6979591836734694 and val rocauc 0.5167561992837391 saved to ./models/best_clf_SAF_split_2.pth\n",
      "Epoch: 0 -- Train Loss: 1.0975 RocAuc = 54.3913 Acc = 69.7959|| Val Loss: 1.0984 RocAuc = 51.6756 Acc = 69.9187\n",
      ">>> Finished training clf_SAF_split_2 model and saved to ./models/lattest_clf_SAF_split_2.pth, final metrics: train aucroc 0.5439130995932245 , train acc 0.6979591836734694 and val acc 0.6991869918699187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb92faf09094acf96b302a21bf4ecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.14754098360655737 at epoch 0 with train aucroc 0.6079055722257598 , train acc 0.15071283095723015 and val rocauc 0.6864321752092649 saved to ./models/best_clf_SAF_split_3.pth\n",
      "Epoch: 0 -- Train Loss: 1.0937 RocAuc = 60.7906 Acc = 15.0713|| Val Loss: 1.0994 RocAuc = 68.6432 Acc = 14.7541\n",
      ">>> Finished training clf_SAF_split_3 model and saved to ./models/lattest_clf_SAF_split_3.pth, final metrics: train aucroc 0.6079055722257598 , train acc 0.15071283095723015 and val acc 0.14754098360655737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b67114e284fee91cd391bb38a57b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.14754098360655737 at epoch 0 with train aucroc 0.5753989845964474 , train acc 0.15071283095723015 and val rocauc 0.42163742690058476 saved to ./models/best_clf_SAF_split_4.pth\n",
      "Epoch: 0 -- Train Loss: 1.0879 RocAuc = 57.5399 Acc = 15.0713|| Val Loss: 1.1015 RocAuc = 42.1637 Acc = 14.7541\n",
      ">>> Finished training clf_SAF_split_4 model and saved to ./models/lattest_clf_SAF_split_4.pth, final metrics: train aucroc 0.5753989845964474 , train acc 0.15071283095723015 and val acc 0.14754098360655737\n",
      ">>> Training model for Pro peace,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b898f37abdb8474f9bc2268c787ed17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.9186991869918699 at epoch 0 with train aucroc 0.5 , train acc 0.9163265306122449 and val rocauc 0.5 saved to ./models/best_clf_Pro peace,_split_0.pth\n",
      "Epoch: 0 -- Train Loss: 0.7190 RocAuc = 50.0000 Acc = 91.6327|| Val Loss: 0.6946 RocAuc = 50.0000 Acc = 91.8699\n",
      ">>> Finished training clf_Pro peace,_split_0 model and saved to ./models/lattest_clf_Pro peace,_split_0.pth, final metrics: train aucroc 0.5 , train acc 0.9163265306122449 and val acc 0.9186991869918699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3f05950268442188f3f3eaeb51829c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.9186991869918699 at epoch 0 with train aucroc 0.5 , train acc 0.9163265306122449 and val rocauc 0.5 saved to ./models/best_clf_Pro peace,_split_1.pth\n",
      "Epoch: 0 -- Train Loss: 0.7079 RocAuc = 50.0000 Acc = 91.6327|| Val Loss: 0.6939 RocAuc = 50.0000 Acc = 91.8699\n",
      ">>> Finished training clf_Pro peace,_split_1 model and saved to ./models/lattest_clf_Pro peace,_split_1.pth, final metrics: train aucroc 0.5 , train acc 0.9163265306122449 and val acc 0.9186991869918699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3c2c395df441768ebe0fd96a047c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.08943089430894309 at epoch 0 with train aucroc 0.5 , train acc 0.08163265306122448 and val rocauc 0.5 saved to ./models/best_clf_Pro peace,_split_2.pth\n",
      "Epoch: 0 -- Train Loss: 0.6914 RocAuc = 50.0000 Acc = 8.1633|| Val Loss: 0.6928 RocAuc = 50.0000 Acc = 8.9431\n",
      ">>> Finished training clf_Pro peace,_split_2 model and saved to ./models/lattest_clf_Pro peace,_split_2.pth, final metrics: train aucroc 0.5 , train acc 0.08163265306122448 and val acc 0.08943089430894309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa0c3462d8541c49c52e3947ecae6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.08196721311475409 at epoch 0 with train aucroc 0.5 , train acc 0.0835030549898167 and val rocauc 0.5 saved to ./models/best_clf_Pro peace,_split_3.pth\n",
      "Epoch: 0 -- Train Loss: 0.6881 RocAuc = 50.0000 Acc = 8.3503|| Val Loss: 0.6936 RocAuc = 50.0000 Acc = 8.1967\n",
      ">>> Finished training clf_Pro peace,_split_3 model and saved to ./models/lattest_clf_Pro peace,_split_3.pth, final metrics: train aucroc 0.5 , train acc 0.0835030549898167 and val acc 0.08196721311475409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc29acaf7d404614ba77f20db9dde4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.9180327868852459 at epoch 0 with train aucroc 0.5 , train acc 0.9164969450101833 and val rocauc 0.5 saved to ./models/best_clf_Pro peace,_split_4.pth\n",
      "Epoch: 0 -- Train Loss: 0.7001 RocAuc = 50.0000 Acc = 91.6497|| Val Loss: 0.6933 RocAuc = 50.0000 Acc = 91.8033\n",
      ">>> Finished training clf_Pro peace,_split_4 model and saved to ./models/lattest_clf_Pro peace,_split_4.pth, final metrics: train aucroc 0.5 , train acc 0.9164969450101833 and val acc 0.9180327868852459\n",
      ">>> Training model for anti peace\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb19408465e42f8bc1e60c8aa39e8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.06504065040650407 at epoch 0 with train aucroc 0.5 , train acc 0.0673469387755102 and val rocauc 0.5 saved to ./models/best_clf_anti peace_split_0.pth\n",
      "Epoch: 0 -- Train Loss: 0.7041 RocAuc = 50.0000 Acc = 6.7347|| Val Loss: 0.6939 RocAuc = 50.0000 Acc = 6.5041\n",
      ">>> Finished training clf_anti peace_split_0 model and saved to ./models/lattest_clf_anti peace_split_0.pth, final metrics: train aucroc 0.5 , train acc 0.0673469387755102 and val acc 0.06504065040650407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6460d4d4df9473ca99152e8661fa7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.9349593495934959 at epoch 0 with train aucroc 0.5 , train acc 0.9326530612244898 and val rocauc 0.5 saved to ./models/best_clf_anti peace_split_1.pth\n",
      "Epoch: 0 -- Train Loss: 0.6869 RocAuc = 50.0000 Acc = 93.2653|| Val Loss: 0.6930 RocAuc = 50.0000 Acc = 93.4959\n",
      ">>> Finished training clf_anti peace_split_1 model and saved to ./models/lattest_clf_anti peace_split_1.pth, final metrics: train aucroc 0.5 , train acc 0.9326530612244898 and val acc 0.9349593495934959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106f1103deb343768744e7235d86ef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.926829268292683 at epoch 0 with train aucroc 0.5 , train acc 0.9346938775510204 and val rocauc 0.5 saved to ./models/best_clf_anti peace_split_2.pth\n",
      "Epoch: 0 -- Train Loss: 0.6929 RocAuc = 50.0000 Acc = 93.4694|| Val Loss: 0.6931 RocAuc = 50.0000 Acc = 92.6829\n",
      ">>> Finished training clf_anti peace_split_2 model and saved to ./models/lattest_clf_anti peace_split_2.pth, final metrics: train aucroc 0.5 , train acc 0.9346938775510204 and val acc 0.926829268292683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9edfe516d6a409486e8f017e574adcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.06557377049180328 at epoch 0 with train aucroc 0.5 , train acc 0.06720977596741344 and val rocauc 0.5 saved to ./models/best_clf_anti peace_split_3.pth\n",
      "Epoch: 0 -- Train Loss: 0.7120 RocAuc = 50.0000 Acc = 6.7210|| Val Loss: 0.6950 RocAuc = 50.0000 Acc = 6.5574\n",
      ">>> Finished training clf_anti peace_split_3 model and saved to ./models/lattest_clf_anti peace_split_3.pth, final metrics: train aucroc 0.5 , train acc 0.06720977596741344 and val acc 0.06557377049180328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0bceb7417a4c78829ff23454d50359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best VAL ACC so far: 0.9344262295081968 at epoch 0 with train aucroc 0.5 , train acc 0.9327902240325866 and val rocauc 0.5 saved to ./models/best_clf_anti peace_split_4.pth\n",
      "Epoch: 0 -- Train Loss: 0.6890 RocAuc = 50.0000 Acc = 93.2790|| Val Loss: 0.6932 RocAuc = 50.0000 Acc = 93.4426\n",
      ">>> Finished training clf_anti peace_split_4 model and saved to ./models/lattest_clf_anti peace_split_4.pth, final metrics: train aucroc 0.5 , train acc 0.9327902240325866 and val acc 0.9344262295081968\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# Function to compute class weights to address class imbalance\n",
    "def multi_class_weights(data, device):\n",
    "    w = compute_class_weight(class_weight=\"balanced\", classes=np.unique(data), y=data)\n",
    "    w =torch.tensor(w, dtype=torch.float32).to(device=device)\n",
    "    return(w)\n",
    "\n",
    "\n",
    "os.makedirs('../models', exist_ok=True) # Create the models directory if it does not exist\n",
    "# Creat the training Loop for Each Label\n",
    "all_logs = {label: {} for label in labels}# Dictionary to store the logs for each label\n",
    "labels_num_classes = [] # List to store the number of classes for each label (2 for binary and 3 for ternary). The number of classes will be used to create the classifier\n",
    "for i,label in enumerate(labels):\n",
    "    print(f'>>> Training model for {label}')\n",
    "    x = embs.detach().cpu().numpy() # get x values from the embeddings tensor\n",
    "    y = Y[label].to_numpy() # get y values from the current label\n",
    "    num_classes = len(np.unique(y)) # get the number of classes for the current \n",
    "    labels_num_classes.append((label,num_classes))\n",
    "    \n",
    "    # Use Stratified KFold to split the data into n_splits folds\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    # Loop through the splits and train the model\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x, y)):\n",
    "        # Generate the model name based on the label and the split\n",
    "        model_name=f'clf_{label}_split_{i}'\n",
    "        # Extract the train and test data as tensors in the device\n",
    "        x_train, y_train = x[train_index], y[train_index]\n",
    "        x_test, y_test = x[test_index], y[test_index]\n",
    "        x_train= torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "        y_train= torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "        x_test = torch.tensor(x_test , dtype=torch.float32, device=device)\n",
    "        y_test = torch.tensor(y_test , dtype=torch.float32, device=device)\n",
    "\n",
    "        # Create the datasets and dataloaders\n",
    "        train_ds = TweetsDataset(x_train, y_train)\n",
    "        test_ds = TweetsDataset(x_test, y_test)\n",
    "        train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "        test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create the model, optimizer and loss function\n",
    "        model = TweetClassifer(embeddings_dim, num_classes, hidden_dim=hidden_dim).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=multi_class_weights(data=y, device=device))\n",
    "\n",
    "        # Train the model\n",
    "        model, logs = train(model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_fn, num_classes, model_name, device)\n",
    "        all_logs[label][i] = logs\n",
    "\n",
    "# Save the logs using torch.save\n",
    "os.makedirs('../logs', exist_ok=True)\n",
    "torch.save(all_logs, '../logs/stratified_logs.pth')\n",
    "\n",
    "#Finally, rename the models with the best validation F1 score across all splits for each label\n",
    "for label in all_logs:\n",
    "    f1 = -float('inf')\n",
    "    best_split = None\n",
    "    for split in all_logs[label]:\n",
    "        logs = all_logs[label][split]\n",
    "        if logs['val_f1'][-1] > f1:\n",
    "            f1 = logs['val_f1'][-1]\n",
    "            best_split = split\n",
    "    best_split_model_path = f'../models/best_clf_{label}_split_{best_split}.pth'\n",
    "    new_model_path = f'../models/clf_{label}.pth'\n",
    "    shutil.copy(best_split_model_path, new_model_path)\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warwick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
